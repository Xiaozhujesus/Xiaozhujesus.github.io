<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stay Foolish, Stay Hungry!</title>
    <link>https://xiaozhujesus.github.io/</link>
    <description>Recent content on Stay Foolish, Stay Hungry!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Tue, 14 Apr 2020 21:48:55 +0800</lastBuildDate>
    
	<atom:link href="https://xiaozhujesus.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>线程模型</title>
      <link>https://xiaozhujesus.github.io/post/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Tue, 14 Apr 2020 21:48:55 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</guid>
      <description>进程是资源管理的最小单位，线程是程序执行的最小单位。在操作系统设计上，从进程演化出线程，最主要的目的就是更好的支持 SMP 以及减小（进程/线程）上下文切换开销
而线程模型主要有两种，一种是内核线程，一种是用户线程，分类依据是线程调度是在内核还是用户态，前者更利于并发使用多处理器的资源，而后者则更多考虑的是上下文切换开销；主流商用系统中，通常都将两者结合起来使用，既提供内核线程以满足 smp 系统的需要，也支持用线程库的方式在用户态实现另一套线程机制，此时一个内核线程同时成为多个用户态线程的调度者，调度器在用户态实现
在核外实现的线程又可以分为&amp;quot;一对一&amp;rdquo;、&amp;ldquo;多对一&amp;quot;两种模型，前者用一个核心进程（也许是轻量进程）对应一个线程，将线程调度等同于进程调度，交给内核完成（Java），而后者则完全在核外实现多线程（golang），调度也在用户态完成。后者就是前面提到的单纯的用户级线程模型的实现方式，显然，这种核外的线程调度器实际上只需要完成线程运行栈的切换，调度开销非常小，但同时因为核心信号（无论是同步的还是异步的）都是以进程为单位的，因而无法定位到线程，所以这种实现方式不能用于多处理器系统
Linux 内核只提供了轻量进程的支持，限制了更高效的线程模型的实现，但 Linux 着重优化了进程的调度开销，一定程度上也弥补了这一缺陷。目前最流行的线程机制 LinuxThreads 所采用的就是线程-进程&amp;quot;一对一&amp;quot;模型，调度交给核心，而在用户级实现一个包括信号处理在内的线程管理机制
当初 Linux 被开发出来的时候，其内核并不真正地支持多线程。多线程最初是由 LinuxThreads 这个工程带入到 Linux 的,由于 clone 系统调用创建了调用进程的副本，而且可以和父进程共享地址空间；通过 clone，LinuxThreads 完全在用户空间模拟了线程。然而，这种方法有很多的缺陷，并没有符合 POSIX 的要求，特别是在信号处理，调度和进程间同步原语等方面
为了改进 LinuxThreads，很明显需要内核的支持，而且需要重写线程库，红帽发起了 Native POSIX Thread Library，NPTL 项目，NPTL 采用了一对一的线程模型，即用户态线程与内核线程一一对应</description>
    </item>
    
    <item>
      <title>Java Volatile</title>
      <link>https://xiaozhujesus.github.io/post/java-volatile/</link>
      <pubDate>Sun, 12 Apr 2020 10:25:18 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/java-volatile/</guid>
      <description>volatile 关键字标记 Java 变量在 main memory 而不是 cache，每次读取从 main memory 读，每次更新写回 main memory，除此之外还有一些其他的保证，下面介绍下
变量可见性问题 volatile 保证变量更新后的跨线程的可见性，看下面的例子：
public class SharedObject { public int counter = 0; } 假设两个线程访问该变量，thread1 会更新变量，而 thread2 只读变量，如果变量 counter 不声明为 volatile，那么 thread1 对变量的更新不保证何时写回 main memory，更新可能只是存在 cache 中，所以此时 cache 和 main memory 中 counter 的值是不一致的；另外，即使 thread1 将新的值写回 main memory 了，由于 thread2 的所在 CPU 的 cache 中可能始终是旧值，所以也不一定能看到新的值
Java volatile 可见性保证 volatile 用于保证变量可见性问题，声明为 volatile 的变量，所有对变量的更新都会写回 main memory，而且对变量的访问也会从 main memory 读取，对于上面的情况，将变量声明为 volatile 足够了，但是如果两个线程都要更新变量，只是将变量声明为 volatile 还不够，还需要同步</description>
    </item>
    
    <item>
      <title>Concurrency Model</title>
      <link>https://xiaozhujesus.github.io/post/concurrency-model/</link>
      <pubDate>Sat, 11 Apr 2020 18:02:07 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/concurrency-model/</guid>
      <description>并发模型指定了系统中的线程如何协作完成给定的任务，不同的并发模型对给定任务的划分方式不同，通信和协作方式也不同；本文将会讨论几种并发模型
并发模型和分布式系统的相似性 并发系统中，不同线程通信协作，分布式系统中，多个进程通信协作，这些进程可能在不同的计算节点上，所以通常你会看到不同的并发模型与对应的分布式系统架构有相似之处；当然分布式系统还面临其他问题，比如网络不通，节点上的进程挂了
共享状态 vs 分离状态  并发模型比较重要的方面就是决定线程之间是否共享数据，当共享状态时候，就要考虑竞争和死锁等问题，当然也由线程如何使用共享变量来决定
分离状态，线程之间不共享任何数据，这种情况线程间需要通信，交换不可变对象或者交换数据的副本，因此当两个线程更新数据，由于数据是副本，每个线程都有各自的，所以可以避免大部分并发问题
状态分离的并发模型通常来说更容易实现，因为对数据的操作没有竞争，不需要考虑并发访问问题，但是需要从整体仔细考虑应用的设计，但这也是值得的，下面开始介绍几种并发模型
parallel worker 并发模型 新任务会被分发给不同的 worker，如下图所示
delegator 会将新的任务分发给不同的 worker，每个 worker 会从头到尾完成完整的任务，并且是并发完成的（包括并行），java.util.concurrent 工具包中的许多并发工具都设计用于这种模型
parallel worker 模型的优势 好理解，容易扩展，增加并行性只需要增加 worker 即可
parallel worker 模型的劣势 简单，容易理解的背后也隐藏着一些缺点
共享状态会让事情变得复杂 大多数情况下，parallel worker 模型要比上面介绍的复杂，worker 间在完成整个任务期间总是会访问或更新共享状态，要么是内存，或者是数据库，如下图所示：
只要存在多线程共享状态的情况，线程就需要以确保一个线程对共享数据的更新对其他线程可见的方式访问共享数据（将其刷新到主内存中，而不仅仅是缓存在执行该线程的 CPU 的 cache 中），同时线程需要避免竞争条件，死锁和许多其他共享状态并发问题。
另外，当线程访问共享数据，相互等待时，并行度会降低，许多共享数据结构是阻塞的，导致某一时刻最多只有有限数量的线程可以访问，而且这样会导致多线程激烈的竞争，激烈的竞争会浪费总线资源，而且某种程度上将导致失去并发，而是顺序执行
非阻塞算法可以降低竞争，提升性能，但是非阻塞算法很难实现
不可变数据结构是另一种选择，其实是多版本；不可变数据结构在修改后始终保留其自身的先前版本。 因此，如果多个线程持有相同的不可变数据结构的引用，并且一个线程对其进行了修改，则修改线程将获得对新结构的引用。 所有其他线程保留对旧结构的引用，该旧结构仍保持不变，因此是一致的
这也存在一些问题，例如，一个不可变 list 会将所有新元素添加到 list 的开头，并返回对新添加元素的引用（该引用随后指向列表的其余部分）。 所有其他线程仍保留对 list 中先前第一个元素的引用，并且对这些线程而言，列表保持不变，他们看不到新添加的元素。
这样的不可变 list 被实现为 linked list。 不幸的是，list 在现代硬件上的表现不佳。 list 中的每个元素都是一个单独的对象，这些对象可以分布在整个计算机的内存中。 现代 CPU 顺序访问数据的速度要快得多，因此在现代硬件上，使用 arraylist 实现的 list 中可以获得更高的性能，因为数组顺序存储数据。 CPU 高速缓存可以一次将更大的 array 加载到高速缓存中，并让 CPU 在加载后直接访问 CPU 高速缓存中的数据。 对于 linked list，其元素是分散在整个 RAM 上的，所以实际不可能完全将 list 的所有元素都加载到 cache 中</description>
    </item>
    
    <item>
      <title>Java Memory Model</title>
      <link>https://xiaozhujesus.github.io/post/java-memory-model/</link>
      <pubDate>Sat, 11 Apr 2020 10:55:04 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/java-memory-model/</guid>
      <description>Jvm 是一个完整的计算机模型，因此自然包括内存模型（类似 Linux 下的虚拟内存模型），而 JMM 说明了 Jvm 如何使用物理机的内存的
写正确的并发代码需要理解 Java 内存模型，Java 内存模型说明了不同线程如何，何时可以观察到对共享变量的修改，以及如何同步对共享变量的访问，下面介绍的内存模型直到 Java8
Jvm 使用的 Java 内存模型将内存划分为堆和栈，下图展示了 JMM 的逻辑视图
每个线程有自己的调用栈，每次调用方法就会产生新的栈帧，每个栈帧中包含方法的局部变量，线程只能访问自己的栈帧，而且局部变量对其他线程不可见，因此即使两个线程执行相同的方法，但由于有各自的栈帧，因此局部变量也是各自版本的，而且无法相互访问；
所有基本类型的局部变量都存储在栈上（boolean, byte, short, char, int, long, float, double），所有对象都存储在堆上，包括基本类型的包装类，局部变量也可能是对象引用，这种情况引用变量存储在栈上，引用的对象存储在堆上；对象的成员变量存储在堆上，不论成员变量是基本数据类型还是引用数据类型；static 类变量也存储在堆上，
硬件内存架构 硬件内存架构与 Java 内存模型不同，理解硬件内存架构也很重要，这样可以理解 Java 内存模型是如何与硬件内存架构一起工作的，下面描述一般的硬件内存架构，SMP，如下图：
现代计算机通常有两个或多个 CPU，每个 CPU 有可能有多个 core，每个 core 可以运行一个线程，这些线程完全是并行运行的（区分并发），距离 CPU 越近的存储，CPU 在上面完成操作的速度越快，cache 通常是多级的，这里我们不关心这个，关键是要理解是存在 cache 层的，而且 cache 和 register 是 CPU 私有的，main memory 是 CPU 共享的，当需要访问数据时候，首先从 register 中找，如果不明中，从 cache 中找，如果不明中，从 memory 中找，之后将结果缓存在 cache 中；当操作完成需要写回结果时，首先将 register 中的结果写到 cache 中，之后在某个时间点例如 cache 中的空间不足时候，将结果刷回 main memory；每次 cache 更新不需要操作全部 cache，而是以 cache line 为单位进行更新</description>
    </item>
    
    <item>
      <title>Java Synchronized</title>
      <link>https://xiaozhujesus.github.io/post/java-synchronized/</link>
      <pubDate>Sat, 11 Apr 2020 09:50:58 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/java-synchronized/</guid>
      <description>Synchronized and Data Visibility 如果不使用 synchronized 或者 volatile 关键字，就无法保证当一个线程更新共享变量时候，其他线程何时能看到该更新结果；主要是两个问题：
 更新过的值在寄存器或者 CPU 私有 cache 中，何时刷新到主存 其他线程何时更新自己寄存器或者私有 cache 中过期的旧值  synchronized 关键字可以保证上述两点成立，当线程进入 synchronized 代码块，会从主存同步所有与其他线程共享当值，也就是可以看到最新的值，当线程退出 synchronized 代码块时，所有对线程共享变量的修改都会从寄存器或者私有 cache 中刷新到主存；所以类似 volatile 关键字的作用
synchronized 还可以防止 Java 编译器和虚拟机乱序执行代码，为了获得更好的性能，通常 Java 编译器和虚拟机会对指令的执行顺序进行调整，如果在 synchronized 代码块内的对变量的修改操作，经过指令重排序后在 synchronized 代码块之前执行，就会发生很奇怪的现象；因此 synchronized 代码块中的代码不会进行指令重排序
在那些对象上进行同步？ 不要在 String 对象和基本类型包装类对象上进行同步，因为编译器会进行优化，你以为你用的是不同的对象，实际上是相同的对象
synchronized(&amp;#34;Hey&amp;#34;) { //do something in here. } 如果你在不同的地方使用字符串&amp;quot;Hey&amp;quot;进行同步，那么其实使用的是常亮池中的相同对象，基本类型包装类也一样
synchronized(Integer.valueOf(1)) { //do something in here. } 所以建议使用 this 或者 new Object()进行同步，jvm 不会缓存和重用这些对象
synchronized 的限制以及替代  多个线程对变量的访问有 read 也有 write，而且 read 比较多，当多个线程同时 read 时候，synchronized 过于严格，可以使用 read/write Lock 最多同时允许 N 个线程进入同步代码块，使用 Semaphore 实现 synchronized 不提供公平行，进入同步代码块的顺序不是线程请求的顺序 如果只有一个线程写，其他线程读，可以使用 volatile 而不需要 synchronized 只将需要同步的代码放入 synchronized，减小 synchronized 块的大小，可以增加并行性  可重入性 synchronized 在同一个线程上是可重入的</description>
    </item>
    
    <item>
      <title>Virtualization Basic</title>
      <link>https://xiaozhujesus.github.io/post/virtualization-basic/</link>
      <pubDate>Sun, 29 Mar 2020 10:40:57 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/virtualization-basic/</guid>
      <description>Platform Virtualization Alice 的公司有个软件产品运行在 windows 平台上；Bob 的公司也有个一款软件产品需要运行，但是他不关心底层平台的细节，只要这个平台可以提供他的产品运行所需的资源和抽象就可以了，如下图所示
图中的 blackbox 就是虚拟平台，要解决的问题是如何让 Bob 的软件产品感觉其运行在真实的平台上而不是给他一个真正的平台 虚拟化是要充分利用资源，比如上午时候 Alice 公司的内存需求是 8G，而 Bob 公司的需求是 1G，但是下午 Alice 公司的需求是 2G，而 Bob 需求 5G，如果 Alice 直接购买最大值 8G，Bob 购买 5G，一共 13G，但是从全局看其实一共只需要 9G 就可以满足两个公司的需求；
其实虚拟化技术是操作系统设计中的 service 扩展部分（例如微内核中，各种 filesystem，netstack 都是运行在非内核态的服务，这样方便扩展），只不过应用的粒度有些大而已，在整个 OS 范围内进行虚拟化，而不是 service 扩展
Hypervisor 如上图所示，如何保证多个 OS 同时运行在共享的硬件平台上？谁来决定哪个 OS 哪个时刻占有硬件资源？这里需要一个 OS 的 OS，通常叫做 virtual machine manager 或者 hypervisor，运行在共享硬件平台上的多个 OS 称为 virtual machine（VM）或者 guest OS，有两种 hypervisor，下面分别介绍
Native Hypervisor（bare metal） Hosted Hypervisor hosted hypervisor 包括 VMware，Workstation 和 Virtual Box；后面主要介绍 native hypervisor</description>
    </item>
    
    <item>
      <title>Virtualization</title>
      <link>https://xiaozhujesus.github.io/post/virtualization/</link>
      <pubDate>Sun, 29 Mar 2020 10:34:14 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/virtualization/</guid>
      <description>分以下 4 个方面介绍虚拟化内容
 虚拟化基础 内存虚拟化 CPU 虚拟化 设备虚拟化  </description>
    </item>
    
    <item>
      <title>Lock</title>
      <link>https://xiaozhujesus.github.io/post/lock/</link>
      <pubDate>Sat, 28 Mar 2020 11:34:30 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/lock/</guid>
      <description>P1 P2     modify struct(A); wait for mod;    use struct(A);    假设只有 read/write 原子操作指令，能实现上面的两个进程的需求么？可以的 使用一个共享变量解决，flag = 0;//int
   P1 P2     mod(A) while (flag == 0 );   flag = 1;//signal P2 use(A)    flag = 0;//re-init    注意上面的所有操作都是 read/write 内存访问，都是原子操作；flag 变量是同步变量，struct A 是普通数据
原子操作 看一个简单互斥锁的实现
lock(L): if(L == 0) &amp;lt;--- L = 1; | else | while(L==1); | //wait | go back; ------ unlock(L): L = 0; 只用原子 read/write 操作可以实现上面的互斥锁么？注意，上面的 if(L == 0) L = 1;实际上需要 3 条指令来完成，首先从内存读变量 L，然后检查是否为 0，如果是，向内存位置 L 存入新的值 1；这 3 条指令必须以原子不可分的方式执行才能保证算法的正确性；虽然单个的 read/write 操作是原子的，但是一组 read/write 操作就不是原子的了；所以为了正确实现互斥锁，我们需要新的原子指令，语意为从内存读数据，然后修改，最后写回内存（read,modify,write，简称 rmw）</description>
    </item>
    
    <item>
      <title>Shared Memory Machine Model</title>
      <link>https://xiaozhujesus.github.io/post/shared-memory-machine-model/</link>
      <pubDate>Thu, 26 Mar 2020 11:51:38 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/shared-memory-machine-model/</guid>
      <description>介绍 3 种不同结构的共享内存机器模型，共享内存意思是每个 CPU 都可以访问所有内存空间，但缓存是每个 CPU 独有的，无法相互访问
Dance Hall Architecture SMP Architecture Symmetric Multiprocessor，对称是因为每个 cpu 的访存时间相同，
Distributor Shared Memory Architecture 每个 CPU 有一个关联的内存，每个 CPU 都可以通过系统总线访问到其他 CPU 关联的内存，但是访问自己的内存比较快
Shared Memory And Caches 这里以 SMP 架构为例进行讲解。
单 CPU 架构下，CPU 访问内存时，首先访问 cache，如果 cache 命中，则直接访问，否则访问内存，同时将结果缓存在 cache 中；多 CPU 架构下 cache 的作用与单 CPU 一样，但是有个问题就是 cache 是 CPU 私有的，memory 是 CPU 共享的，假设内存有个热点变量 var 值为 y，缓存在所有 CPU 的 cache 中，当 cpu1 对私有 cache 中的 var 修改时，假设修改后的值为 x，那么所有 CPU 的 cache 中的 var 现在都应该是 x，这点应该由谁来保证呢？</description>
    </item>
    
    <item>
      <title>Synchronization</title>
      <link>https://xiaozhujesus.github.io/post/synchronization/</link>
      <pubDate>Tue, 24 Mar 2020 07:59:55 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/synchronization/</guid>
      <description>共享内存模型下的同步元语  互斥锁（mutual exclusive lock）：同时最多只能有一个线程使用 共享锁（shared lock）：多个线程可以同时使用，通常是读锁 屏障（barrier）：所有线程都到达，才能继续执行  后面我们每个分别讨论</description>
    </item>
    
    <item>
      <title>Sequential Consistency</title>
      <link>https://xiaozhujesus.github.io/post/sequential-consistency/</link>
      <pubDate>Fri, 20 Mar 2020 09:24:15 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/sequential-consistency/</guid>
      <description>顺序一致性是并发系统很强的安全属性。 非正式地，顺序一致性意味着操作似乎以某种 total order 进行，并且该顺序与每个单独进程上操作的顺序一致。
顺序一致性不具有完全可用性或强可以用性（totally or sticky available）。 如果发生网络分区，则某些或所有节点将无法前进。
顺序一致的系统中的一个进程可能比其他进程领先或落后。 例如，他可以读取任意陈旧状态。 但是，一旦进程 A 观察到了来自进程 B 的某些操作，就永远无法观察到 B 之前的状态。再加上 total order 属性，使得顺序一致性对于程序员来说成为了很强的模型。
当您需要实时约束时（例如，您想通过 side channel 将事件告知其他进程，并让该进程观察到相应事件），请尝试 linearizability。 如果您需要 total availability，而又不需要 total order，请尝试因果一致性（causal consistency）。
莱斯利·兰珀特（Leslie Lamport）在 1979 年的论文《如何制造能正确执行多进程程序的多处理器计算机》中定义了顺序一致性。 他使用“顺序一致”：
the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program</description>
    </item>
    
    <item>
      <title>PRAM</title>
      <link>https://xiaozhujesus.github.io/post/pram/</link>
      <pubDate>Fri, 20 Mar 2020 09:00:26 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/pram/</guid>
      <description>PRAM (Pipeline Random Access Memory)来自于 Lipton 和 Sandberg 于 1988 年发表的论文《 PRAM：一种可扩展的共享存储器 》，它试图放宽现有的一致性存储器模型以获得更好的并发性（从而提高性能）。 它强制在任何地方观察到单个进程执行的任何成对写入的结果与那个进程执行它们的顺序相同。 但是，来自不同进程的写入可能会以不同顺序被观察到。
PRAM 完全等同于读取写入，单调写入和单调读取
PRAM 具有高可用性：在存在网络分区的情况下，只要客户端始终坚持使用同一服务器，所有进程都可以前进而不阻塞
对于更严格的一致性模型（该模型还强制执行写入后读取操作），请尝试因果一致性（causal consistency）：因为它是可用的，并且提供了更直观的语义。 如果需要总体可用性（total availability），请考虑牺牲读取写入的内容，而仅选择单调读取+单调写入。
PRAM 更抽象的定义： 如果会话顺序（session order，每个进程的操作顺序）是可见性顺序（visibility order，给定操作可见的操作）的子集，则满足 PRAM。
参考：PRAM</description>
    </item>
    
    <item>
      <title>SSL</title>
      <link>https://xiaozhujesus.github.io/post/ssl/</link>
      <pubDate>Thu, 12 Mar 2020 18:20:20 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/ssl/</guid>
      <description>PKI，CA和数字证书 PKI就是 Public Key Infrastructure的缩写，翻译过来就是公开密钥基础设施。它是利用公开密钥技术所构建的，解决网络安全问题的，普遍适用的一种基础设施;是一种遵循既定标准的密钥管理平台,它能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系。
PKI既不是一个协议，也不是一个软件，它是一个标准，在这个标准之下发展出的为了实现安全基础服务目的的技术统称为PKI。可以说CA(认证中心)是PKI的核心，而数字证书是PKI的最基本元素
CA 为保证用户之间在网上传递信息的安全性、真实性、可靠性、完整性和不可抵赖性
CA 机构，又称为证书认证中心 (Certificate Authority) 中心，是一个负责发放和管理数字证书的第三方权威机构，它负责管理PKI结构下的所有用户(包括各种应用程序)的证书，把用户的公钥和用户的其他信息捆绑在一起，在网上验证用户的身份。CA机构的数字签名使得攻击者不能伪造和篡改证书。
认证中心主要有以下5个功能：
 证书的颁发：接收、验证用户(包括下级认证中心和最终用户)的数字证书的申请。可以受理或拒绝 证书的更新：认证中心可以定期更新所有用户的证书，或者根据用户的请求来更新用户的证书 证书的查询：查询当前用户证书申请处理过程；查询用户证书的颁发信息，这类查询由目录服务器ldap来完成 证书的作废：由于用户私钥泄密等原因，需要向认证中心提出证书作废的请求；证书已经过了有效期，认证中心自动将该证书作废。认证中心通过维护证书作废列表 (Certificate Revocation List,CRL) 来完成上述功能。 证书的归档：证书具有一定的有效期，证书过了有效期之后就将作废，但是我们不能将作废的证书简单地丢弃，因为有时我们可能需要验证以前的某个交易过程中产生的数字签名，这时我们就需要查询作废的证书。  X.509标准 &amp;ldquo;SSL证书&amp;quot;这个词是一个相对较大的概念，整个PKI体系中有很多SSL证书格式标准。PKI的标准规定了PKI的设计、实施和运营，规定了PKI各种角色的&amp;quot;游戏规则&amp;rdquo;，提供数据语法和语义的共同约定。x.509是PKI中最重要的标准，它定义了公钥证书的基本结构，可以说PKI是在X.509标准基础上发展起来的
SSL公钥证书格式 1. 证书版本号(Version) 版本号指明X.509证书的格式版本，现在的值可以为: 1) 0: v1 2) 1: v2 3) 2: v3 也为将来的版本进行了预定义 2. 证书序列号(Serial Number) 序列号指定由CA分配给证书的唯一的&amp;quot;数字型标识符&amp;quot;。当证书被取消时，实际上是将此证书的序列号放入由CA签发的CRL中， 这也是序列号唯一的原因。 3. 签名算法标识符(Signature Algorithm) 签名算法标识用来指定由CA签发证书时所使用的&amp;quot;签名算法&amp;quot;。算法标识符用来指定CA签发证书时所使用的: 1) 公开密钥算法 2) hash算法 example: sha256WithRSAEncryption 须向国际知名标准组织(如ISO)注册 4. 签发机构名(Issuer) 此域用来标识签发证书的CA的X.500 DN(DN-Distinguished Name)名字。包括: 1) 国家(C) 2) 省市(ST) 3) 地区(L) 4) 组织机构(O) 5) 单位部门(OU) 6) 通用名(CN) 7) 邮箱地址 5.</description>
    </item>
    
    <item>
      <title>Ldap基础</title>
      <link>https://xiaozhujesus.github.io/post/ldap%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Thu, 12 Mar 2020 11:34:41 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/ldap%E5%9F%BA%E7%A1%80/</guid>
      <description>LDAP是一款轻量级目录访问协议（Lightweight Directory Access Protocol,LDAP），基于X.500标准，且支持TCP/IP协议；默认以Berkeley DB作为后端数据库，对于一次写入、多次查询和搜索的操作能够提供较好的支持；基于C/S架构，非常适合用于实现账号的集中管理和维护。本文将对LDAP的基本概念、常用命令以及基本操作进行简要介绍
基本概念 LDAP数据组织方式 LDAP默认使用Berkeley DB作为后端数据库，主要以散列的数据类型（如键值对）来组织数据。对于LDAP中的数据记录，Berkeley从中提取指定属性组来作为该记录的标识名（可定位到该记录的目录），并将这些属性按树状结构来组织，与关系型数据库相比，可显著提高查询性能。典型的LDAP的目录组织结构如下图所示：
entry 条目，也称记录项，是LDAP中存储和组织数据的基本单元，对LDAP相关的增、删、改、查等操作都是以条目为基本单元的。例如，每一个用户的相关信息在LDAP中都是以条目的形式存储和使用的，包括该用户的标识名以及其他属性。每一个条目都有一个标识名（distinguished name,dn），用于在LDAP中唯一地标识该条目；LDAP中条目的标识名即是该条目的目录，例如，对于用户userA，其标识名为&amp;quot;dn:uid=userA,ou=People,dc=zenandidi,dc=com&amp;rdquo;。
attribute 属性，用于描述条目包含的相关信息。LDAP中的属性可分为必要属性(MUST)和可选属性(MAY)两种，新建条目时，必须为必要属性赋值；除定义中指明&amp;quot;SINGLE-VALUE&amp;quot;外，默认情况下，属性可具有多个值。人员组织机构中有如下常见属性：
   属性 描述 举例     uid (user id) 指用户的登录名称 uid=userA   cn (common name) 指用户的全名 cn=userA   sn (sur name) 指用户的姓氏 sn=wang   mail 指用户的邮箱地址 mail: userA@gmail.com   telephoneNumber 指用户的联系方式 telephoneNumber: 123456   ou (organizationalUnit) 指一个组织单位的名称 ou=people   dc (domain component) 指一个域名 dc=baidu,dc=com   c (country name) 指一个国家的名称 c: CN   rdn (relative dn) 指用户的相对标识名 uid=userA   objectClass 内置属性，该对象中包含的属性可供条目使用 objectClass: inetOrgPerson    objectClass LDAP中，一个条目(Entry)必须包含一个对象类(objectClass)属性，且需要赋予至少一个值。每一个值将用作一条LDAP条目进行数据存储的模板；模板中包含了一个条目必须被赋值的属性和可选的属性。通过组合不同的对象类，可方便的定义条目。</description>
    </item>
    
    <item>
      <title>Ldap安装</title>
      <link>https://xiaozhujesus.github.io/post/ldap%E5%AE%89%E8%A3%85/</link>
      <pubDate>Thu, 12 Mar 2020 11:02:14 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/ldap%E5%AE%89%E8%A3%85/</guid>
      <description>安装前环境准备 在安装OPENLDAP之前需要关闭防火墙
[wz]# systemctl stop firewalld.service [wz]# systemctl disable firewalld.service OPENLDAP-servers安装及配置 安装 [wz]# yum install -y openldap-servers 配置  配置管理员密码  [wz]# slappasswd -s passwd {SSHA}2e1yDU9g9VSc8UArkfpi5KsjT9mSZxCN 修改配置文件  olcDbDirectory：指定ldap数据库的路径；
olcSuffix：指定管理员管理的目录树根域；
olcRootDN：指定管理员dn；
olcRootPW：该字段需要自行添加，用于指定管理员密码，将上一步生成的加密字符串添加在这一行；
[wz]# vim /etc/openldap/slapd.d/cn\=config/olcDatabase\=\{2\}hdb.ldif # AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify. # CRC32 1763c834 dn: olcDatabase={2}hdb objectClass: olcDatabaseConfig objectClass: olcHdbConfig olcDatabase: {2}hdb olcDbDirectory: /var/lib/ldap olcSuffix: dc=com olcRootDN: cn=Manager,dc=com olcRootPW: {SSHA}2e1yDU9g9VSc8UArkfpi5KsjT9mSZxCN olcDbIndex: objectClass eq,pres olcDbIndex: ou,cn,mail,surname,givenname eq,pres,sub structuralObjectClass: olcHdbConfig entryUUID: b5baf318-0bee-1039-9713-29cc6215f8f1 creatorsName: cn=config createTimestamp: 20190516062222Z entryCSN: 20190516062222.</description>
    </item>
    
    <item>
      <title>Logical Clock 和 Vector Clock</title>
      <link>https://xiaozhujesus.github.io/post/logical-clock-%E5%92%8C-vector-clock/</link>
      <pubDate>Sun, 01 Mar 2020 19:12:46 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/logical-clock-%E5%92%8C-vector-clock/</guid>
      <description>Logical Clock lamport 逻辑时钟算法：
 每个事件对应一个 Lamport 时间戳，初始值为 0 如果事件在节点内发生，时间戳加 1 如果事件属于发送事件，时间戳加 1 并在消息中带上该时间戳 如果事件属于接收事件，时间戳 = Max(本地时间戳，消息中的时间戳) + 1  三个机器上各自跑着一个进程，分别为 P1,P2,P3，由于不同的机器上的物理时钟、CPU 负载、或者 CPU 频率不一样，所以不同的机器上的时钟速率可能是不同的，例当 P1 所在的机器 tick 了 6 次，P2 所在的机器 tick 了 8 次，就是异步网络中指的漂移时钟不同。
完</description>
    </item>
    
  </channel>
</rss>