<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Stay Foolish, Stay Hungry!</title>
    <link>https://xiaozhujesus.github.io/post/</link>
    <description>Recent content in Posts on Stay Foolish, Stay Hungry!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Sun, 19 Jul 2020 20:41:20 +0800</lastBuildDate>
    
	<atom:link href="https://xiaozhujesus.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Zab</title>
      <link>https://xiaozhujesus.github.io/post/zab/</link>
      <pubDate>Sun, 19 Jul 2020 20:41:20 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/zab/</guid>
      <description>outstanding transaction:被提出但是为提交
zab 使用 FIFO channal 通信，可以同时处理多个 outstanding transaction；但是 Paxos 并不要求使用 FIFO channel 进行通信，所以消息有可能丢失或者乱序，因此不可以有多个 outstanding transaction，每次只能处理一个 transaction，吞吐量比较低；可以将多个有顺序要求的更新请求封装到一个请求中来解决，但是效率还是很低
3 个阶段 Zab 协议有 3 个阶段
 discovery synchronization broadcast  每个进程按 3 个阶段的顺序执行该协议，进程可以中途放弃本轮协议的执行，开始新一轮协议的执行，例如执行到第二阶段后放弃执行，从第一阶段开始重新执行
2 种角色 Zab 协议中有两种角色，leader 和 follower，论文中引入了 leader oracle 这样一个逻辑组件，原文如下：
Each process implements a leader oracle, and the leader oracle provides the identifier of the prospective leader l.
也就是说，每个进程实现了一个 leader oracle，是用来在选举开始时候，协商选举出 prospective leader 节点的；在第一阶段，进程咨询其 leader oracle ，应该 follow 哪个节点，即哪个节点为 prospective leader，被 leader oracle 选为 prospective leader 还无法成为真正的 leader，还需要经过第二阶段才可以</description>
    </item>
    
    <item>
      <title>Raft</title>
      <link>https://xiaozhujesus.github.io/post/raft/</link>
      <pubDate>Tue, 14 Jul 2020 17:07:25 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/raft/</guid>
      <description>raft 分为两个部分，leader 选举和日志备份
每个 server 在 3 种 state 中的一个：leader, follower, or candidate follower 不主动发送 request，只是响应 leader 和 candidate 的请求
使用 RPC 通信，有两种 RPC：RequestVote RPC 和 AppendEntries RPC，前者用于 leader 选举，后者用于心跳（没有日志内容的 AppendEntries RPC）和日志备份，节点会以定时的方式不断发送 RPC，直到该 RPC 收到响应
leader 选举 leader 周期发送心跳给 follower，当 follower 在 election timeout 周期内没有收到 leader 的心跳时候，状态改为 candidate，然后开始发起新一轮选举
 增加 current term，state 转换为 candidate， 给自己投票，并发送 RequestVote RPC 给集群其他节点  节点会一直重复上面的步骤直到下面一种情况发生：
 赢得选举 其他节点赢得选举 超时还没有选举出 leader  赢得选举 在每个 term 投票中，每个节点只能投一票，当某个节点收到相同 term 超过半数节点的支持时候，就赢得选举；超过半数规则保证了每个 term 只能有一个 leader；赢得选举后，节点向其他节点发送心跳，阻止进一步选举</description>
    </item>
    
    <item>
      <title>CAP</title>
      <link>https://xiaozhujesus.github.io/post/cap/</link>
      <pubDate>Wed, 08 Jul 2020 20:03:51 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/cap/</guid>
      <description>分布式系统有 3 个指标：
 Consistency Availability Partition tolerance  加州大学的计算机科学家 Eric Brewer 指出，这三个指标不可能同时满足
Consistency 一致性分为很多种：
 弱一致性（Weak）：写入一个数据 a 成功后，在数据副本上可能读出来，也可能读不出来，不能保证多长时间之后每个副本的数据一定是一致的。 最终一致性（Eventually）：写入一个数据 a 成功后，在其他副本有可能读不到 a 的最新值，但在某个时间窗口之后保证最终能读到，可以看做弱一致性的一个特例，这里面的重点是这个时间窗口。 强一致性（Strong）：数据 a 一旦写入成功，在任意副本任意时刻都能读到 a 的最新值。  最终一致性还可以继续细分，大家更喜欢把除了弱一致性和强一致性的其他一致性全部归为最终一致性。
弱一致性和最终一致性的副本同步是采用异步的方式，而强一致性一般要求同步更新副本，然后才能返回成功，否则很难满足任意副本任意时刻都能读到最新值，异步的通常意味着更好的吞吐量，但也意味着更复杂的架构，更复杂的开发、调试。同步意味着简单，但也意味着响应时间更长，吞吐量的更低。
 Backups，通常不会用在生产环境； M/S，master/slave,可以异步，也可以同步，写是瓶颈点； MM，multi-master，可以解决写的问题，复杂度在于如何解决冲突； 2PC，2 Phase Commit，强一致，性能低，不高可用； Paxos，它是完全分布的。没有单一的主协调员  从图中可以看出，如果要满足强一致性，有两种方案：
 2PC，吞吐量低，响应时间高，随着节点数增加，性能指数级下降 Paxos，实现成本较高，不过现在有 raft 了，容易实现，容易理解  CAP 定理中的一致性是指强一致性，也就是所有 client 节点访问同一份最新的数据副本
Availability 每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据
Partition tolerance 以实际效果而言，分区容错相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择，很明显，如果在发生分区时，选择了 C，意味着所有节点都需要同步更新数据后才能给 client 返回结果，而由于网络分区，系统会卡在这里导致不可用，也就是失去了 A；如果发生分区时候选择了 A，意味着需要给 client 返回请求结果，那么就会在无法更新所有节点的情况下给 client 返回响应，同时访问到分区内节点的 client 得到的就是旧的数据，导致失去了 C；如果没有发生分区，那么 C 和 A 是可以同时满足的</description>
    </item>
    
    <item>
      <title>Java Interrupt</title>
      <link>https://xiaozhujesus.github.io/post/java-interrupt/</link>
      <pubDate>Thu, 02 Jul 2020 09:37:05 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/java-interrupt/</guid>
      <description>Java 中停止一个线程不能用 stop，因为 stop 会瞬间强行停止一个线程，且该线程持有的锁并不能释放。大家多习惯于用 interrupt，那么使用它又有什么需要注意的呢？
interrupt 相关的方法 public boolean isInterrupted() public void interrupt() public static boolean interrupted() boolean isInterrupted() 每个线程都一个状态位用于标识当前线程对象是否是中断状态。isInterrupted 主要用于判断当前线程对象的中断标志位是否被标记了，如果被标记了则返回 true，表示当前已经被中断，否则返回 false。我们也可以看看它的实现源码：
public boolean isInterrupted() { return isInterrupted(false); } private native boolean isInterrupted(boolean ClearInterrupted); 底层调用的 native 方法 isInterrupted，传入一个 boolean 类型的参数，用于指定调用该方法之后是否需要清除该线程的中断标识位。从这里我们也可以看出来，调用 isInterrupted()并不会清除线程的中断标识位。
void interrupt() interrupt()用于设置当前线程对象的中断标识位，其源码为：
public void interrupt() { // 检查当前线程是否有权限修改目标线程，如果没有，则会抛出异常SecurityException  if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) { Interruptible b = blocker; if (b != null) { interrupt0(); // Just to set the interrupt flag  b.</description>
    </item>
    
    <item>
      <title>Java FutureTask</title>
      <link>https://xiaozhujesus.github.io/post/java-futuretask/</link>
      <pubDate>Wed, 01 Jul 2020 09:15:00 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/java-futuretask/</guid>
      <description>package java.util.concurrent; import java.util.concurrent.locks.LockSupport; /** * A cancellable asynchronous computation. This class provides a base * implementation of {@link Future}, with methods to start and cancel a * computation, query to see if the computation is complete, and retrieve the * result of the computation. The result can only be retrieved when the * computation has completed; the {@code get} methods will block if the * computation has not yet completed.</description>
    </item>
    
    <item>
      <title>Sequentially Consistent Paper</title>
      <link>https://xiaozhujesus.github.io/post/sequentially-consistent-paper/</link>
      <pubDate>Sat, 27 Jun 2020 07:31:52 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/sequentially-consistent-paper/</guid>
      <description>处理器也许不会按照程序顺序执行指令，执行的正确性得以保证如果满足如下条件：
执行结果与顺序执行程序的结果一样，感觉是废话。。。满足这个条件的处理器是 sequential 的
现在考虑这样的计算机，由许多个这样的处理器组成，这些处理器访问共享内存，要想保证多处理器程序执行的正确性，需要满足下面的条件：
所有处理器指令的执行总的看是按照某种 sequential order，而在这个总的执行序列中，每个单独的处理器所执行的指令是按照程序指定的顺序，满足这个条件的多处理器是 sequentially consistent 的
注意，每个单独处理器的 sequentiality 并不能保证多处理器计算是 sequentially consistent 的，从上面的定义也可以看出，因为单独处理器的 sequentiality，表示处理器执行指令可以不按照程序指定的顺序，只要保证结果是对的，即与按照程序指定顺序执行结果是一样的；但是多处理器的 sequentially consistent 要求在总的执行序列中，每个单独处理器执行的指令，一定与程序指定的顺序一致，不可进行指令重排序；原因是这些指令有可能是用来在多个处理器直接同步数据访问的指令，如果重新排序，就无法保证数据同步了（下面的例子可以看出来）
文中描述了在多处理器，共享内存模型下，处理器和内存需要满足什么要求，才能保证程序正确性，在这种模型下，处理器之间只能通过共享内存通信，处理器操作我们只关心两种：从内存读数据的 fetch，和向内存写数据的 store，每个处理器的执行序列由这两种操作组成
文中说的并发程序使用的还是 two-process，即两个进程组成的程序，因为写论文时候还没有线程，所以是多进程程序；lamport 老哥举了个例子来演示问题；例子是一个互斥协议，两个进程每个都包含 critical section，协议的目的就是保证任何时刻最多只有一个进程可以执行 critical section 的代码
process 1 a := 1; if b = 0 then critical section; a = 0; else ... fi process 2 b := 1; if a = 0 then critical section; b = 0; else ... fi 说明下上面伪代码的符号，:= 是赋值，= 是比较，变量 a 和 b 初始为 0</description>
    </item>
    
    <item>
      <title>Disk</title>
      <link>https://xiaozhujesus.github.io/post/disk/</link>
      <pubDate>Sun, 24 May 2020 08:54:30 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/disk/</guid>
      <description>磁盘结构 扇区 512 字节，是磁盘读写单位，block 由多个扇区组成，是软件创建的逻辑组，用来提高读写效率，通常 4 或 8K 字节 注意，OS 每次磁盘读写操作，总是访问至少一个 block
磁盘如何连接到计算机系统
磁盘控制器作用：
 Control movement of disk heads Select a sector on a track Transfers data between disk surface and main memory Disk controller has an internal buffer to store read/write data to/from disk 1 disk controller can control n disks  硬盘结构
从上面看
 Platters are 2-sided and magnetic Platters rotates (about 10000 RPM) All disk heads move at the same time (in or out) Platter has circular tracks Tracks are divided into sectors Sector = the unit of write operation for a disk  However:Sector is too small to be efficient</description>
    </item>
    
    <item>
      <title>AQS</title>
      <link>https://xiaozhujesus.github.io/post/aqs/</link>
      <pubDate>Fri, 22 May 2020 08:31:39 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/aqs/</guid>
      <description>package java.util.concurrent.locks; import java.util.concurrent.TimeUnit; import java.util.ArrayList; import java.util.Collection; import java.util.Date; import sun.misc.Unsafe; public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { private static final long serialVersionUID = 7373984972572414691L; protected AbstractQueuedSynchronizer() { } static final class Node { /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; /** waitStatus value to indicate thread has cancelled */ static final int CANCELLED = 1; /** waitStatus value to indicate successor&amp;#39;s thread needs unparking */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; final boolean isShared() { return nextWaiter == SHARED; } final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } Node() { // Used to establish initial head or SHARED marker  } Node(Thread thread, Node mode) { // Used by addWaiter  this.</description>
    </item>
    
    <item>
      <title>JNI</title>
      <link>https://xiaozhujesus.github.io/post/jni/</link>
      <pubDate>Fri, 22 May 2020 08:26:29 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/jni/</guid>
      <description>JNI Java native interface，jvm 用来调用具体平台上的 native 代码（通常是 C 和 C++）的方法
1.原理 native executable 程序通常可以使用 static 或 shared 的 lib
 static lib 通常在链接阶段会被链接到最终的可执行程序中 shared lib，最终的可执行文件只包含共享库的引用而不是代码  JNI 使用的就是 shared lib 技术实现的，我理解应该是 jvm（C++写的）调用 shared lib，这些文件以 .so/.dll/.dylib结尾，既不在 class 文件里，也不在 jvm 里；jvm 构造一个指针表，表中的指针指向 native method 的内存地址，这样就可以调用 native method 了
1.1 需要的组件  Java code，class 中至少包含一个 native method native code，通常使用 C/C++编写 JNI header file，是个 C/C++头文件，包含所有 JNI 元素的定义（jni.h） C/C++ Compiler，编译出 native shared library  1.2 代码中的 JNI 元素 Java 部分  任何声明为 native 的 method 都必须在 native shared library 中实现 System.</description>
    </item>
    
    <item>
      <title>Linux File</title>
      <link>https://xiaozhujesus.github.io/post/linux-file/</link>
      <pubDate>Thu, 21 May 2020 08:00:00 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/linux-file/</guid>
      <description>大多数文件 IO 用到 5 个函数，这些函数是系统调用而不是库函数，会陷入内核
 open read write lseek close  open 必选项如下：
 O_RDONLY O_WRONLY O_RDWR O_EXEC O_SEARCH  可选项如下：
 O_APPEND O_CLOEXEC O_CREAT O_DIRECTORY O_EXCL O_NOFOLLOW O_NOBLOCK O_TRUNC O_SYNC O_DSYNC O_RSYNC  这里主要说下可选项的后三个
O_SYNC 每次 write 等待物理 IO 操作完成，包括由该 write 引起的文件属性更新所需要的 IO
O_DSYNC 每次 write 要等待物理 IO 操作完成，但是如果该写操作并不影响读取刚写入的数据，则不需要等待文件属性被更新
O_DSYNC 与 O_SYNC 有微妙的区别，仅当文件属性需要更新以反映文件数据变化时候，例如更新文件大小以反应文件中有更多数据，就可以看出二者的区别；设置 O_SYNC 后文件数据和属性总是同步更新，而 O_DSYNC 选项，当使用 write 重写文件现有部分内容时候，文件时间属性不会同步更新，但是会更新，只是 write 返回时候只是保证数据被更新了，而文件元数据则会在稍后某个时间更新
O_RSYNC 使得每个以文件描述符为参数的 read 操作等待，直至所有对文件同一部分挂起的写操作都完成
Solaris 支持所有这 3 个选项，而 Linux 处理 O_RSYNC 与处理 O_SYNC 相同</description>
    </item>
    
    <item>
      <title>TCP常见异常与原因</title>
      <link>https://xiaozhujesus.github.io/post/tcp%E5%B8%B8%E8%A7%81%E5%BC%82%E5%B8%B8%E4%B8%8E%E5%8E%9F%E5%9B%A0/</link>
      <pubDate>Fri, 01 May 2020 09:08:19 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/tcp%E5%B8%B8%E8%A7%81%E5%BC%82%E5%B8%B8%E4%B8%8E%E5%8E%9F%E5%9B%A0/</guid>
      <description>TCP 特点  可靠性，通过 ack 实现，如果没有收到 ack，tcp 自动重传数据并等待更长时间，数次重传失败后，才会放弃然后会向应用层返回一个错误 含有持续估算 RTT 的算法，以便知道等待一个 ack 需要多久 有序和幂等，数据流中每个字节都关联一个序号，接收端会根据序号对数据包重排序，将有序数据传递给应用层；收到来自对端的重复数据（根据序号判断），直接丢弃重复数据 流量控制，告知对端自己的接收窗口大小，即接收缓冲区当前可用容量 拥塞控制，防止网络中流量过大导致路由器丢包 全双工，因此 tcp 必须为每个方向上跟踪数据流序号和窗口大小等状态信息  3 次握手，4 次挥手
状态转换图
3 次握手建立连接 client 需要告知对方在即将要建立的连接上，发送数据的初始序列号，通过 syn 包完成，而可靠性需要对该包进行 ack；由于是双工，server 也一样需要这两个包，server 对 client 的 ack 和其对 client 的 syn 可以合并在一起，因此三次握手；
另外，需要 ack 的包都是消耗序列号的，不论是 syn 还是 fin，还是有效数据，ack 本身不消耗序列号，因为 ack 本身不需要 ack
4 次挥手断开连接 主动结束端发送 fin 包，被动结束端对其进行 ack；双工各自结束不影响，因此每个方向的结束都需要这两个包，因此通常需要 4 个包；使用通常是因为，第一个 fin 包可能随数据包一起发送；另外，被动关闭一方的 ack 可能和其 fin 一起发送
发送 fin 包是应用进程调用 shutdown 或者 close 函数导致的，不过当一个 unix 进程不论自愿（调用 exit 或者 main 结束了）还是非自愿（被信号 kill 了），所有打开的描述符都被关闭，这也会导致任何打开的 tcp 连接上发送一个 fin</description>
    </item>
    
    <item>
      <title>共识与一致性</title>
      <link>https://xiaozhujesus.github.io/post/%E5%85%B1%E8%AF%86%E4%B8%8E%E4%B8%80%E8%87%B4%E6%80%A7/</link>
      <pubDate>Fri, 24 Apr 2020 19:24:04 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/%E5%85%B1%E8%AF%86%E4%B8%8E%E4%B8%80%E8%87%B4%E6%80%A7/</guid>
      <description>本文介绍二者的区别与联系
一致性 分布式系统中的多个节点，针对其维护的数据，在约定协议的保证下，使其对外界呈现的值是一致的；一致性大致分为：
 严格一致性 强一致性 弱一致性 最终一致性  其中强一致性又分为顺序一致性和线性一致性
共识 共识是分布式系统中多个节点之间，彼此对某个变量达成一致值的过程；实践中，要保障系统满足不同程度的一致性，往往需要通过共识算法来完成
共识算法 共识算法主要解决分布式系统中，对于某个提案，多个节点达成一致意见的过程；而提案的含义在分布式系统中非常广泛，例如多个事件发生的顺序，某个键对应的值，哪个节点是 leader 等；可以粗略认为任何可以达成一致的信息都可以是提案；对于分布式系统而言，每个节点都是确定性状态机模型（亦称为状态机复制问题，state-machine-replication），从相同的初始状态开始，接受相同顺序的指令，则可以保证相同的结果状态；因此系统中最关键的是，对发生的多个事件的顺序达成共识，即排序；
根据解决的是拜占庭错误还是非拜占庭错误情况，共识算法可以分为 Crash Fault Tolerance(CFT)和 Byzantine Fault Tolerance(BFT)类算法
CFT 算法 包括 Paxos，Raft，及其变种，这类容错算法性能比较好，处理较快，容忍不超过一半的故障节点
BFT 算法 对于要容忍拜占庭错误的情况
共识与一致性的区别 一致性指分布式系统多个副本对外呈现的数据状态，描述了多个节点对数据状态的维护能力；共识则表示分布式系统中多个节点间，彼此对某个提案达成一致意见的过程；因此一致性描述的是状态，共识是过程手段；达成共识并不意味着保证了一致性（强一致），只能说共识机制实现了某种程度上的一致性</description>
    </item>
    
    <item>
      <title>Paxos</title>
      <link>https://xiaozhujesus.github.io/post/paxos/</link>
      <pubDate>Fri, 24 Apr 2020 19:16:23 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/paxos/</guid>
      <description>共识问题的要求  safety   只能选择已经被提出的值 最终只有一个提案值被选定，但是节点可以选择临时的提案值   liveness   所有正常节点可以在有限时间内对单个提案达成共识，并且系统可以持续对外提供服务  FLP 定理 异步系统中的一组进程无法对一个布尔类型的值达成共识，即使只有单个进程出现未知的故障，核心问题是异步
定理指出：在异步系统中，不可能保证 safety 和 liveness 两个性质同时满足，即使出现一点未知的故障；但是定理没有说明，我们可以有多接近同时满足这两个性质
备份状态机 通常使用日志备份实现，所有 server 以相同的顺序执行相同的命令，这样如果每个 server 的初始状态相同，那么最终状态也相同；日志备份是关键，需要保证每个 server 上的日志内容一致，使用共识算法对日志的第 i 条记录应该是什么命令达成共识
Paxos completely-safe 并且 largely-live 的共识协议
Basic Paxos  提案：例如，日志的第 i 条记录是什么命令 提案值：例如，日志的第 i 条记录是 x=1，即将 x 的值赋值为 1  基本 paxos 是指对单提案达成共识，例如，日志第 10 条记录应该是 x=1
 一个或者多个节点可以针对相同的提案提出自己的提案值 只有一个提案值可以被最终选定  Multi Paxos 对日志文件的不同记录，使用不同的 Basic Paxos 来确定相应记录的值
系统角色：  Proposers：处理 client 请求，提出提案，并根据 acceptor 的响应最终决定 commit 还是开启新一轮提案 Acceptors：响应 Proposers 提出的提案，accept/reject；本地记录决策过程；主动学习被选择的提案值  每个节点可以实现超过一种角色，实际实现中，某个节点通常同时实现 2 种角色</description>
    </item>
    
    <item>
      <title>3-PC</title>
      <link>https://xiaozhujesus.github.io/post/3-pc/</link>
      <pubDate>Fri, 24 Apr 2020 18:43:58 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/3-pc/</guid>
      <description>3-PC 是对 2-PC 的改进，将 2-PC 中的第一阶段拆分为两个阶段，CanCommit 和 PreCommit 如下：
CanCommit 阶段  协调者向所有参与者发送一个包含事务的 CanCommit 请求，并等待 ack； 参与者收到该请求后，会尝试锁定执行事务所需相关资源，如果锁定成功，则返回 yes；否则返回 no  PreCommit 阶段 协调者根据响应决定是否进行 preCommit 操作，分为两种情况：
 收到的都是 yes   协调者向所有参与者发送 preCommit 请求 参与者接收到 preCommit 请求后，执行事务，记录 undo 和 redo 日志 执行成功，返回 yes 给协调者  收到有 no 的响应或者等待超时   协调者向所有参与者发送 abort 请求 参与者无论是收到协调者的 abort 请求，还是等待协调者的请求超时，都会 abort 事务 向协调者发送 no 响应  DoCommit 阶段 协调者根据上一阶段的响应决定是否 doCommit
 收到了所有参与者的 yes   向所有参与者发送 doCommit 请求 所有参与者收到 doCommit 后，commit 事务，返回 ack 给协调者  收到了 no 或者等待某些参与者的上一阶段响应超时了   向所有参与者发送 abort 请求 所有参与者收到 abort 后，abort 事务，返回 ack 给协调者  注意，协议规定当进入第 3 阶段时候，参与者只要没有收到 abort，就会对事务进行 commit，不论是等待协调者超时，还是收到 commit 指令</description>
    </item>
    
    <item>
      <title>2-PC</title>
      <link>https://xiaozhujesus.github.io/post/2-pc/</link>
      <pubDate>Fri, 24 Apr 2020 16:09:42 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/2-pc/</guid>
      <description>2PC，即 Two-Phrase Commit 的缩写，是一种一致性协议，首先在数据库领域解决备份一致性问题，有两类角色，协调者和参与者，协议内容如下
prepare 阶段  协调者向所有参与者发送事务内容，等待响应； 协调者收到事务内容，执行事务，并记录 redo 和 undo 日志 协调者将事务执行结果反馈给协调者，如果事务执行成功，返回 yes 响应；否则返回 no 响应  commit 阶段 协调者根据所有参与者的响应来决定是否执行提交操作
 如果所有参与者反馈的都是 yes 响应，则通知所有参与者 commit 如果有参与者返回 no 响应，则通知所有参与者 rollback 如果有参与者在上一阶段没有响应，超时了，则通知所有参与者 rollback 等待参与者的 ack  所有节点都会记录操作日志
两阶段提交的问题 单点问题 只有一个协调者，如果协调者挂了，整个系统不可用；协调者恢复后可以根据本地日志进行恢复，使系统达到一致的状态
参与者挂了，系统也不可用 因为协调者等不到响应，超时会 rollback，无论提交什么事务，都无法完成执行；
如果参与者在第一阶段挂了，分为两种情况：
 参与者在收到事务之前挂了 参与者在收到事务并且执行之后挂了 不论是哪种情况，协调者都收不到 ack，timeout 会 rollback，等故障节点恢复后，如果没有未完成事务，即第 1 中情况，整个系统是一致的，直接对外提供服务；如果发现有未完成事务，说明是第 2 种情况，向协调者询问事务结果，得到 rollback 的消息后，会 rollback 从而整个系统数据一致，然后对外提供服务  如果参与者在第二阶段挂了，也分两种情况：
 参与者在收到 commit 或者 rollback 之前挂了，没有收到消息，第二阶段没有 ack；而其他参与者收到消息执行了 commit 或者 rollback，并返回 ack； 参与者在收到消息并执行 commit 或者 rollback 后挂了，没有 ack；而其他参与者收到消息执行了 commit 或者 rollback，并返回 ack  不论是上述哪种情况，协调者发现有参与者没有 ack 后，都不会接受新的事务了，否则系统不一致；需要等到故障节点恢复，并且整个系统恢复到数据一致性后才对外提供服务；故障节点恢复时，发现没有未完成事务，说明是第 2 种情况，整个系统是数据一致的，系统直接对外提供服务；如果有未完成事务，会向协调者询问事务结果，并进行响应操作（commit 或者 rollback，第一阶段只可能是 rollback），从而使整个系统数据保持一致，然后提供服务</description>
    </item>
    
    <item>
      <title>Java Wait Notify</title>
      <link>https://xiaozhujesus.github.io/post/java-wait-notify/</link>
      <pubDate>Tue, 14 Apr 2020 22:19:59 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/java-wait-notify/</guid>
      <description>线程之间通过共享对象进行同步 public class Flag{ private volatile boolean hasDataToProcess = false; public boolean hasDataToProcess(){ return this.hasDataToProcess; } public void setHasDataToProcess(boolean hasData){ this.hasDataToProcess = hasData; } } 两个线程可以通过同一个 Flag 类的实例进行通信，线程 A 通过 setHasDataToProcess(true)方法通知线程 B 可以开始处理数据了，线程 B 通过 hasDataToProcess()方法知道可以开始处理数据了
Busy Wait 上面的方法中，线程 B 会不断的调用 hasDataToProcess()方法查询是否可以开始处理数据，对于 CPU 资源而言是一种浪费
while(!flag.hasDataToProcess()){ //do nothing... busy waiting } wait,notify,notifyAll 如果等待的时间很短，可以使用 busy wait 的方式，也叫自旋锁，这样可以避免由用户太陷入内核的开销（注意，由用户态陷入内核态，只是由用户态线程切换到对应的内核态线程，但还是这个执行流，注意是线程的切换，开销相对还能小一点；还有一种线程的切换是在进程内，一条执行流的内核线程阻塞了，所以调度同一进程内的另一个执行流执行，过程是由内核线程切换到另一个内核线程，然后由另一个内核线程切换到对应的用户态线程；通常说的上下文切换应该是进程的切换，开销最大，比切换线程开销大很多）；否则，让忙等线程让出 CPU 资源，等条件为真时候再次调度等待的线程运行，这样是比较合理的；Java 中的 wait，notify，notifyAll 提供了这样的功能
wait(), notify(), and notifyAll()是 Object 对象提供的 native 方法，调用上面 3 个函数的时候需要首先获取同步对象的监视器锁，即必须在 synchronized 块中调用，调用 wait 函数，从而进入对象的 wait queue，此时线程处于 waiting 状态，同时释放当前获取到的锁，释放锁会导致唤醒 entry queue 中的 blocked 状态的线程（OS 的 mutex 提供这种功能）；wait queue 中的线程可以得到调度机会当其他线程调用对象上的 notify 或者 notifyAll 方法，注意，这两个方法不会释放锁，只是将 wait queue 中的线程放到 entry queue 中而已；notify 方法会将 wait queue 中的一个线程放到 entry queue，而 notifyAll 将所有 wait queue 中的线程放到 entry queue；当调用 notify 的线程退出 synchronized 代码块的时候，才会释放对象锁，而锁的释放会导致唤醒所有 entry queue 中的阻塞线程；这些线程开始竞争锁，竞争不到的重新阻塞</description>
    </item>
    
    <item>
      <title>线程模型</title>
      <link>https://xiaozhujesus.github.io/post/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Tue, 14 Apr 2020 21:48:55 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</guid>
      <description>进程是资源管理的最小单位，线程是程序执行的最小单位。在操作系统设计上，从进程演化出线程，最主要的目的就是更好的支持 SMP 以及减小（进程/线程）上下文切换开销
而线程模型主要有两种，一种是内核线程，一种是用户线程，分类依据是线程调度是在内核还是用户态，前者更利于并发使用多处理器的资源，而后者则更多考虑的是上下文切换开销；主流商用系统中，通常都将两者结合起来使用，既提供内核线程以满足 smp 系统的需要，也支持用线程库的方式在用户态实现另一套线程机制，此时一个内核线程同时成为多个用户态线程的调度者，调度器在用户态实现
在核外实现的线程又可以分为&amp;quot;一对一&amp;rdquo;、&amp;ldquo;多对一&amp;quot;两种模型，前者用一个核心进程（也许是轻量进程）对应一个线程，将线程调度等同于进程调度，交给内核完成（Java），而后者则完全在核外实现多线程（golang），调度也在用户态完成。后者就是前面提到的单纯的用户级线程模型的实现方式，显然，这种核外的线程调度器实际上只需要完成线程运行栈的切换，调度开销非常小，但同时因为核心信号（无论是同步的还是异步的）都是以进程为单位的，因而无法定位到线程，所以这种实现方式不能用于多处理器系统
Linux 内核只提供了轻量进程的支持，限制了更高效的线程模型的实现，但 Linux 着重优化了进程的调度开销，一定程度上也弥补了这一缺陷。目前最流行的线程机制 LinuxThreads 所采用的就是线程-进程&amp;quot;一对一&amp;quot;模型，调度交给核心，而在用户级实现一个包括信号处理在内的线程管理机制
当初 Linux 被开发出来的时候，其内核并不真正地支持多线程。多线程最初是由 LinuxThreads 这个工程带入到 Linux 的,由于 clone 系统调用创建了调用进程的副本，而且可以和父进程共享地址空间；通过 clone，LinuxThreads 完全在用户空间模拟了线程。然而，这种方法有很多的缺陷，并没有符合 POSIX 的要求，特别是在信号处理，调度和进程间同步原语等方面
为了改进 LinuxThreads，很明显需要内核的支持，而且需要重写线程库，红帽发起了 Native POSIX Thread Library，NPTL 项目，NPTL 采用了一对一的线程模型，即用户态线程与内核线程一一对应</description>
    </item>
    
    <item>
      <title>Java Volatile</title>
      <link>https://xiaozhujesus.github.io/post/java-volatile/</link>
      <pubDate>Sun, 12 Apr 2020 10:25:18 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/java-volatile/</guid>
      <description>volatile 关键字标记 Java 变量在 main memory 而不是 cache，每次读取从 main memory 读，每次更新写回 main memory，除此之外还有一些其他的保证，下面介绍下
变量可见性问题 volatile 保证变量更新后的跨线程的可见性，看下面的例子：
public class SharedObject { public int counter = 0; } 假设两个线程访问该变量，thread1 会更新变量，而 thread2 只读变量，如果变量 counter 不声明为 volatile，那么 thread1 对变量的更新不保证何时写回 main memory，更新可能只是存在 cache 中，所以此时 cache 和 main memory 中 counter 的值是不一致的；另外，即使 thread1 将新的值写回 main memory 了，由于 thread2 的所在 CPU 的 cache 中可能始终是旧值，所以也不一定能看到新的值
Java volatile 可见性保证 volatile 用于保证变量可见性问题，声明为 volatile 的变量，所有对变量的更新都会写回 main memory，而且对变量的访问也会从 main memory 读取，对于上面的情况，将变量声明为 volatile 足够了，但是如果两个线程都要更新变量，只是将变量声明为 volatile 还不够，还需要同步</description>
    </item>
    
    <item>
      <title>Concurrency Model</title>
      <link>https://xiaozhujesus.github.io/post/concurrency-model/</link>
      <pubDate>Sat, 11 Apr 2020 18:02:07 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/concurrency-model/</guid>
      <description>并发模型指定了系统中的线程如何协作完成给定的任务，不同的并发模型对给定任务的划分方式不同，通信和协作方式也不同；本文将会讨论几种并发模型
并发模型和分布式系统的相似性 并发系统中，不同线程通信协作，分布式系统中，多个进程通信协作，这些进程可能在不同的计算节点上，所以通常你会看到不同的并发模型与对应的分布式系统架构有相似之处；当然分布式系统还面临其他问题，比如网络不通，节点上的进程挂了
共享状态 vs 分离状态  并发模型比较重要的方面就是决定线程之间是否共享数据，当共享状态时候，就要考虑竞争和死锁等问题，当然也由线程如何使用共享变量来决定
分离状态，线程之间不共享任何数据，这种情况线程间需要通信，交换不可变对象或者交换数据的副本，因此当两个线程更新数据，由于数据是副本，每个线程都有各自的，所以可以避免大部分并发问题
状态分离的并发模型通常来说更容易实现，因为对数据的操作没有竞争，不需要考虑并发访问问题，但是需要从整体仔细考虑应用的设计，但这也是值得的，下面开始介绍几种并发模型
parallel worker 并发模型 新任务会被分发给不同的 worker，如下图所示
delegator 会将新的任务分发给不同的 worker，每个 worker 会从头到尾完成完整的任务，并且是并发完成的（包括并行），java.util.concurrent 工具包中的许多并发工具都设计用于这种模型
parallel worker 模型的优势 好理解，容易扩展，增加并行性只需要增加 worker 即可
parallel worker 模型的劣势 简单，容易理解的背后也隐藏着一些缺点
共享状态会让事情变得复杂 大多数情况下，parallel worker 模型要比上面介绍的复杂，worker 间在完成整个任务期间总是会访问或更新共享状态，要么是内存，或者是数据库，如下图所示：
只要存在多线程共享状态的情况，线程就需要以确保一个线程对共享数据的更新对其他线程可见的方式访问共享数据（将其刷新到主内存中，而不仅仅是缓存在执行该线程的 CPU 的 cache 中），同时线程需要避免竞争条件，死锁和许多其他共享状态并发问题。
另外，当线程访问共享数据，相互等待时，并行度会降低，许多共享数据结构是阻塞的，导致某一时刻最多只有有限数量的线程可以访问，而且这样会导致多线程激烈的竞争，激烈的竞争会浪费总线资源，而且某种程度上将导致失去并发，而是顺序执行
非阻塞算法可以降低竞争，提升性能，但是非阻塞算法很难实现
不可变数据结构是另一种选择，其实是多版本；不可变数据结构在修改后始终保留其自身的先前版本。 因此，如果多个线程持有相同的不可变数据结构的引用，并且一个线程对其进行了修改，则修改线程将获得对新结构的引用。 所有其他线程保留对旧结构的引用，该旧结构仍保持不变，因此是一致的
这也存在一些问题，例如，一个不可变 list 会将所有新元素添加到 list 的开头，并返回对新添加元素的引用（该引用随后指向列表的其余部分）。 所有其他线程仍保留对 list 中先前第一个元素的引用，并且对这些线程而言，列表保持不变，他们看不到新添加的元素。
这样的不可变 list 被实现为 linked list。 不幸的是，list 在现代硬件上的表现不佳。 list 中的每个元素都是一个单独的对象，这些对象可以分布在整个计算机的内存中。 现代 CPU 顺序访问数据的速度要快得多，因此在现代硬件上，使用 arraylist 实现的 list 中可以获得更高的性能，因为数组顺序存储数据。 CPU 高速缓存可以一次将更大的 array 加载到高速缓存中，并让 CPU 在加载后直接访问 CPU 高速缓存中的数据。 对于 linked list，其元素是分散在整个 RAM 上的，所以实际不可能完全将 list 的所有元素都加载到 cache 中</description>
    </item>
    
    <item>
      <title>Java Memory Model</title>
      <link>https://xiaozhujesus.github.io/post/java-memory-model/</link>
      <pubDate>Sat, 11 Apr 2020 10:55:04 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/java-memory-model/</guid>
      <description>Jvm 是一个完整的计算机模型，因此自然包括内存模型（类似 Linux 下的虚拟内存模型），而 JMM 说明了 Jvm 如何使用物理机的内存的
写正确的并发代码需要理解 Java 内存模型，Java 内存模型说明了不同线程如何，何时可以观察到对共享变量的修改，以及如何同步对共享变量的访问，下面介绍的内存模型直到 Java8
Jvm 使用的 Java 内存模型将内存划分为堆和栈，下图展示了 JMM 的逻辑视图
每个线程有自己的调用栈，每次调用方法就会产生新的栈帧，每个栈帧中包含方法的局部变量，线程只能访问自己的栈帧，而且局部变量对其他线程不可见，因此即使两个线程执行相同的方法，但由于有各自的栈帧，因此局部变量也是各自版本的，而且无法相互访问；
所有基本类型的局部变量都存储在栈上（boolean, byte, short, char, int, long, float, double），所有对象都存储在堆上，包括基本类型的包装类，局部变量也可能是对象引用，这种情况引用变量存储在栈上，引用的对象存储在堆上；对象的成员变量存储在堆上，不论成员变量是基本数据类型还是引用数据类型；static 类变量也存储在堆上，
硬件内存架构 硬件内存架构与 Java 内存模型不同，理解硬件内存架构也很重要，这样可以理解 Java 内存模型是如何与硬件内存架构一起工作的，下面描述一般的硬件内存架构，SMP，如下图：
现代计算机通常有两个或多个 CPU，每个 CPU 有可能有多个 core，每个 core 可以运行一个线程，这些线程完全是并行运行的（区分并发），距离 CPU 越近的存储，CPU 在上面完成操作的速度越快，cache 通常是多级的，这里我们不关心这个，关键是要理解是存在 cache 层的，而且 cache 和 register 是 CPU 私有的，main memory 是 CPU 共享的，当需要访问数据时候，首先从 register 中找，如果不明中，从 cache 中找，如果不明中，从 memory 中找，之后将结果缓存在 cache 中；当操作完成需要写回结果时，首先将 register 中的结果写到 cache 中，之后在某个时间点例如 cache 中的空间不足时候，将结果刷回 main memory；每次 cache 更新不需要操作全部 cache，而是以 cache line 为单位进行更新</description>
    </item>
    
    <item>
      <title>Java Synchronized</title>
      <link>https://xiaozhujesus.github.io/post/java-synchronized/</link>
      <pubDate>Sat, 11 Apr 2020 09:50:58 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/java-synchronized/</guid>
      <description>Synchronized and Data Visibility 如果不使用 synchronized 或者 volatile 关键字，就无法保证当一个线程更新共享变量时候，其他线程何时能看到该更新结果；主要是两个问题：
 更新过的值在寄存器或者 CPU 私有 cache 中，何时刷新到主存 其他线程何时更新自己寄存器或者私有 cache 中过期的旧值  synchronized 关键字可以保证上述两点成立，当线程进入 synchronized 代码块，会从主存同步所有线程可访问到的值，也就是可以看到最新的值，当线程退出 synchronized 代码块时，所有对线程可访问到的变量的修改都会从寄存器或者私有 cache 中刷新到主存；所以类似 volatile 关键字的作用
synchronized 还可以防止 Java 编译器和虚拟机乱序执行代码，为了获得更好的性能，通常 Java 编译器和虚拟机会对指令的执行顺序进行调整，如果在 synchronized 代码块内的对变量的修改操作，经过指令重排序后在 synchronized 代码块之前执行，那原来本想同步的代码就没有得到同步；因此 synchronized 代码块中的代码与其之前和之后的代码不会进行指令重排序，但是注意，synchronized 块中的代码还是有可能发生指令重排序的
在哪些对象上进行同步？ 不要在 String 对象和基本类型包装类对象上进行同步，因为编译器会进行优化，你以为你用的是不同的对象，实际上是相同的对象
synchronized(&amp;#34;Hey&amp;#34;) { //do something in here. } 如果你在不同的地方使用字符串&amp;quot;Hey&amp;quot;进行同步，那么其实使用的是常亮池中的相同对象，基本类型包装类也一样
synchronized(Integer.valueOf(1)) { //do something in here. } 所以建议使用 this 或者 new Object()进行同步，java 编译器和 jvm 不会缓存和重用这些对象
synchronized 的限制以及替代  多个线程对变量的访问有 read 也有 write，而且 read 比较多，当多个线程同时 read 时候，synchronized 过于严格，可以使用 read/write Lock 最多同时允许 N 个线程进入同步代码块，使用 Semaphore 实现 synchronized 不提供公平性，当多个线程阻塞等待进入同步代码块，其进入的顺序不一定是线程请求的顺序 如果只有一个线程写，其他线程读，可以使用 volatile 而不需要 synchronized 只将需要同步的代码放入 synchronized，减小 synchronized 块的大小，可以增加并行性  可重入性 synchronized 在同一个线程上是可重入的</description>
    </item>
    
    <item>
      <title>Virtualization Basic</title>
      <link>https://xiaozhujesus.github.io/post/virtualization-basic/</link>
      <pubDate>Sun, 29 Mar 2020 10:40:57 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/virtualization-basic/</guid>
      <description>Platform Virtualization Alice 的公司有个软件产品运行在 windows 平台上；Bob 的公司也有个一款软件产品需要运行，但是他不关心底层平台的细节，只要这个平台可以提供他的产品运行所需的资源和抽象就可以了，如下图所示
图中的 blackbox 就是虚拟平台，要解决的问题是如何让 Bob 的软件产品感觉其运行在真实的平台上而不是给他一个真正的平台 虚拟化是要充分利用资源，比如上午时候 Alice 公司的内存需求是 8G，而 Bob 公司的需求是 1G，但是下午 Alice 公司的需求是 2G，而 Bob 需求 5G，如果 Alice 直接购买最大值 8G，Bob 购买 5G，一共 13G，但是从全局看其实一共只需要 9G 就可以满足两个公司的需求；
其实虚拟化技术是操作系统设计中的 service 扩展部分（例如微内核中，各种 filesystem，netstack 都是运行在非内核态的服务，这样方便扩展），只不过应用的粒度有些大而已，在整个 OS 范围内进行虚拟化，而不是 service 扩展
Hypervisor 如上图所示，如何保证多个 OS 同时运行在共享的硬件平台上？谁来决定哪个 OS 哪个时刻占有硬件资源？这里需要一个 OS 的 OS，通常叫做 virtual machine manager 或者 hypervisor，运行在共享硬件平台上的多个 OS 称为 virtual machine（VM）或者 guest OS，有两种 hypervisor，下面分别介绍
Native Hypervisor（bare metal） Hosted Hypervisor hosted hypervisor 包括 VMware，Workstation 和 Virtual Box；后面主要介绍 native hypervisor</description>
    </item>
    
    <item>
      <title>Virtualization</title>
      <link>https://xiaozhujesus.github.io/post/virtualization/</link>
      <pubDate>Sun, 29 Mar 2020 10:34:14 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/virtualization/</guid>
      <description>分以下 4 个方面介绍虚拟化内容
 虚拟化基础 内存虚拟化 CPU 虚拟化 设备虚拟化  </description>
    </item>
    
    <item>
      <title>Lock</title>
      <link>https://xiaozhujesus.github.io/post/lock/</link>
      <pubDate>Sat, 28 Mar 2020 11:34:30 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/lock/</guid>
      <description>P1 P2     modify struct(A); wait for mod;    use struct(A);    假设只有 read/write 原子操作指令，能实现上面的两个进程的需求么？可以的 使用一个共享变量解决，flag = 0;//int
   P1 P2     mod(A) while (flag == 0 );   flag = 1;//signal P2 use(A)    flag = 0;//re-init    注意上面的所有操作都是 read/write 内存访问，都是原子操作；flag 变量是同步变量，struct A 是普通数据
原子操作 看一个简单互斥锁的实现
lock(L): if(L == 0) &amp;lt;--- L = 1; | else | while(L==1); | //wait | go back; ------ unlock(L): L = 0; 只用原子 read/write 操作可以实现上面的互斥锁么？注意，上面的 if(L == 0) L = 1;实际上需要 3 条指令来完成，首先从内存读变量 L，然后检查是否为 0，如果是，向内存位置 L 存入新的值 1；这 3 条指令必须以原子不可分的方式执行才能保证算法的正确性；虽然单个的 read/write 操作是原子的，但是一组 read/write 操作就不是原子的了；所以为了正确实现互斥锁，我们需要新的原子指令，语意为从内存读数据，然后修改，最后写回内存（read,modify,write，简称 rmw）</description>
    </item>
    
    <item>
      <title>Shared Memory Machine Model</title>
      <link>https://xiaozhujesus.github.io/post/shared-memory-machine-model/</link>
      <pubDate>Thu, 26 Mar 2020 11:51:38 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/shared-memory-machine-model/</guid>
      <description>介绍 3 种不同结构的共享内存机器模型，共享内存意思是每个 CPU 都可以访问所有内存空间，但缓存是每个 CPU 独有的，无法相互访问
Dance Hall Architecture SMP Architecture Symmetric Multiprocessor，对称是因为每个 cpu 的访存时间相同，
Distributor Shared Memory Architecture 每个 CPU 有一个关联的内存，每个 CPU 都可以通过系统总线访问到其他 CPU 关联的内存，但是访问自己的内存比较快
Shared Memory And Caches 这里以 SMP 架构为例进行讲解。
单 CPU 架构下，CPU 访问内存时，首先访问 cache，如果 cache 命中，则直接访问，否则访问内存，同时将结果缓存在 cache 中；多 CPU 架构下 cache 的作用与单 CPU 一样，但是有个问题就是 cache 是 CPU 私有的，memory 是 CPU 共享的，假设内存有个热点变量 var 值为 y，缓存在所有 CPU 的 cache 中，当 cpu1 对私有 cache 中的 var 修改时，假设修改后的值为 x，那么所有 CPU 的 cache 中的 var 现在都应该是 x，这点应该由谁来保证呢？</description>
    </item>
    
    <item>
      <title>OS Synchronization</title>
      <link>https://xiaozhujesus.github.io/post/synchronization/</link>
      <pubDate>Tue, 24 Mar 2020 07:59:55 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/synchronization/</guid>
      <description>共享内存模型下的同步元语  互斥锁（mutual exclusive lock）：同时最多只能有一个线程使用 条件变量（condition variable）：阻塞等待被条件满足，得到通知 信号量（semaphores）： 共享锁（shared lock）：多个线程可以同时使用，通常是读锁 屏障（barrier）：所有线程都到达，才能继续执行  后面我们每个分别讨论</description>
    </item>
    
    <item>
      <title>Sequential Consistency</title>
      <link>https://xiaozhujesus.github.io/post/sequential-consistency/</link>
      <pubDate>Fri, 20 Mar 2020 09:24:15 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/sequential-consistency/</guid>
      <description>顺序一致性不具有完全可用性或强可以用性（totally or sticky available）。 如果发生网络分区，则某些或所有节点将无法前进。
顺序一致的系统中的一个进程可能比其他进程领先或落后。 例如，他可以读取任意陈旧状态。 但是，一旦进程 A 观察到了来自进程 B 的某些操作，就永远无法观察到 B 之前的状态。再加上 total order 属性，使得顺序一致性对于程序员来说成为了很强的模型。
当您需要实时约束时，请使用 linearizability；如果您需要 total availability，而又不需要 total order，请尝试因果一致性（causal consistency）。
莱斯利·兰珀特（Leslie Lamport）在 1979 年的论文《如何制造能正确执行多进程程序的多处理器计算机》中定义了顺序一致性。 他使用“顺序一致”：
the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program
上述定义中隐含了 SMP 系统可能不满足顺序一致性</description>
    </item>
    
    <item>
      <title>Linearizability</title>
      <link>https://xiaozhujesus.github.io/post/linearizability/</link>
      <pubDate>Sat, 14 Mar 2020 07:56:08 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/linearizability/</guid>
      <description>动机 java 和 C++中的对象其实是数据容器，每个对象都定义了一组方法对对象的状态进行操作，对象的类描述了方法的行为，描述对象的行为有很多方法：例如 API；在 sequential model 中，单线程对一组对象操作，不会有什么问题，当多线程共享相同的对象时候，原来的模型失效了，所以需要新的模型来描述对象，这就是 Linearizability;
Linearizability 是并发对象（concurrent object）的正确性条件（correctness condition），也是 execution history 的一个属性，允许程序员使用 sequential model 中的已经存在的技术来说明（specify）和推理（reason about）并发对象；当多个进程并发调用并发对象的方法时候，Linearizability 假设，单个调用在 invocation 和对应的 response 之间的某个点瞬时生效，这个生效的瞬间叫 linearizatioon point；
考虑一个 FIFO 队列，
pic 1
pic 2
pic 3
pic 4
pic 5
下面是并发 FIFO 队列的实现：
class LockBasedQueue&amp;lt;T&amp;gt; { int head, tail; T[] items; Lock lock; public LockBasedQueue(int capacity) { head = 0; tail = 0; ock = new ReentrantLock(); items = (T[]) new Object[capacity]; } public T deq() throws EmptyException { lock.</description>
    </item>
    
    <item>
      <title>SSL</title>
      <link>https://xiaozhujesus.github.io/post/ssl/</link>
      <pubDate>Thu, 12 Mar 2020 18:20:20 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/ssl/</guid>
      <description>PKI，CA 和数字证书 PKI 就是 Public Key Infrastructure 的缩写，翻译过来就是公开密钥基础设施。它是利用公开密钥技术所构建的，解决网络安全问题的，普遍适用的一种基础设施;是一种遵循既定标准的密钥管理平台,它能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系。
PKI 既不是一个协议，也不是一个软件，它是一个标准，在这个标准之下发展出的为了实现安全基础服务目的的技术统称为 PKI。可以说 CA(认证中心)是 PKI 的核心，而数字证书是 PKI 的最基本元素
CA 为保证用户之间在网上传递信息的安全性、真实性、可靠性、完整性和不可抵赖性
CA 机构，又称为证书认证中心 (Certificate Authority) 中心，是一个负责发放和管理数字证书的第三方权威机构，它负责管理 PKI 结构下的所有用户(包括各种应用程序)的证书，把用户的公钥和用户的其他信息捆绑在一起，在网上验证用户的身份。CA 机构的数字签名使得攻击者不能伪造和篡改证书。
认证中心主要有以下 5 个功能：
 证书的颁发：接收、验证用户(包括下级认证中心和最终用户)的数字证书的申请。可以受理或拒绝 证书的更新：认证中心可以定期更新所有用户的证书，或者根据用户的请求来更新用户的证书 证书的查询：查询当前用户证书申请处理过程；查询用户证书的颁发信息，这类查询由目录服务器 ldap 来完成 证书的作废：由于用户私钥泄密等原因，需要向认证中心提出证书作废的请求；证书已经过了有效期，认证中心自动将该证书作废。认证中心通过维护证书作废列表 (Certificate Revocation List,CRL) 来完成上述功能。 证书的归档：证书具有一定的有效期，证书过了有效期之后就将作废，但是我们不能将作废的证书简单地丢弃，因为有时我们可能需要验证以前的某个交易过程中产生的数字签名，这时我们就需要查询作废的证书。  X.509 标准 &amp;ldquo;SSL 证书&amp;quot;这个词是一个相对较大的概念，整个 PKI 体系中有很多 SSL 证书格式标准。PKI 的标准规定了 PKI 的设计、实施和运营，规定了 PKI 各种角色的&amp;quot;游戏规则&amp;rdquo;，提供数据语法和语义的共同约定。x.509 是 PKI 中最重要的标准，它定义了公钥证书的基本结构，可以说 PKI 是在 X.509 标准基础上发展起来的
SSL 公钥证书格式 1. 证书版本号(Version) 版本号指明X.509证书的格式版本，现在的值可以为: 1) 0: v1 2) 1: v2 3) 2: v3 也为将来的版本进行了预定义 2.</description>
    </item>
    
    <item>
      <title>Ldap基础</title>
      <link>https://xiaozhujesus.github.io/post/ldap%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Thu, 12 Mar 2020 11:34:41 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/ldap%E5%9F%BA%E7%A1%80/</guid>
      <description>LDAP是一款轻量级目录访问协议（Lightweight Directory Access Protocol,LDAP），基于X.500标准，且支持TCP/IP协议；默认以Berkeley DB作为后端数据库，对于一次写入、多次查询和搜索的操作能够提供较好的支持；基于C/S架构，非常适合用于实现账号的集中管理和维护。本文将对LDAP的基本概念、常用命令以及基本操作进行简要介绍
基本概念 LDAP数据组织方式 LDAP默认使用Berkeley DB作为后端数据库，主要以散列的数据类型（如键值对）来组织数据。对于LDAP中的数据记录，Berkeley从中提取指定属性组来作为该记录的标识名（可定位到该记录的目录），并将这些属性按树状结构来组织，与关系型数据库相比，可显著提高查询性能。典型的LDAP的目录组织结构如下图所示：
entry 条目，也称记录项，是LDAP中存储和组织数据的基本单元，对LDAP相关的增、删、改、查等操作都是以条目为基本单元的。例如，每一个用户的相关信息在LDAP中都是以条目的形式存储和使用的，包括该用户的标识名以及其他属性。每一个条目都有一个标识名（distinguished name,dn），用于在LDAP中唯一地标识该条目；LDAP中条目的标识名即是该条目的目录，例如，对于用户userA，其标识名为&amp;quot;dn:uid=userA,ou=People,dc=zenandidi,dc=com&amp;rdquo;。
attribute 属性，用于描述条目包含的相关信息。LDAP中的属性可分为必要属性(MUST)和可选属性(MAY)两种，新建条目时，必须为必要属性赋值；除定义中指明&amp;quot;SINGLE-VALUE&amp;quot;外，默认情况下，属性可具有多个值。人员组织机构中有如下常见属性：
   属性 描述 举例     uid (user id) 指用户的登录名称 uid=userA   cn (common name) 指用户的全名 cn=userA   sn (sur name) 指用户的姓氏 sn=wang   mail 指用户的邮箱地址 mail: userA@gmail.com   telephoneNumber 指用户的联系方式 telephoneNumber: 123456   ou (organizationalUnit) 指一个组织单位的名称 ou=people   dc (domain component) 指一个域名 dc=baidu,dc=com   c (country name) 指一个国家的名称 c: CN   rdn (relative dn) 指用户的相对标识名 uid=userA   objectClass 内置属性，该对象中包含的属性可供条目使用 objectClass: inetOrgPerson    objectClass LDAP中，一个条目(Entry)必须包含一个对象类(objectClass)属性，且需要赋予至少一个值。每一个值将用作一条LDAP条目进行数据存储的模板；模板中包含了一个条目必须被赋值的属性和可选的属性。通过组合不同的对象类，可方便的定义条目。</description>
    </item>
    
    <item>
      <title>Ldap安装</title>
      <link>https://xiaozhujesus.github.io/post/ldap%E5%AE%89%E8%A3%85/</link>
      <pubDate>Thu, 12 Mar 2020 11:02:14 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/ldap%E5%AE%89%E8%A3%85/</guid>
      <description>安装前环境准备 在安装OPENLDAP之前需要关闭防火墙
[wz]# systemctl stop firewalld.service [wz]# systemctl disable firewalld.service OPENLDAP-servers安装及配置 安装 [wz]# yum install -y openldap-servers 配置  配置管理员密码  [wz]# slappasswd -s passwd {SSHA}2e1yDU9g9VSc8UArkfpi5KsjT9mSZxCN 修改配置文件  olcDbDirectory：指定ldap数据库的路径；
olcSuffix：指定管理员管理的目录树根域；
olcRootDN：指定管理员dn；
olcRootPW：该字段需要自行添加，用于指定管理员密码，将上一步生成的加密字符串添加在这一行；
[wz]# vim /etc/openldap/slapd.d/cn\=config/olcDatabase\=\{2\}hdb.ldif # AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify. # CRC32 1763c834 dn: olcDatabase={2}hdb objectClass: olcDatabaseConfig objectClass: olcHdbConfig olcDatabase: {2}hdb olcDbDirectory: /var/lib/ldap olcSuffix: dc=com olcRootDN: cn=Manager,dc=com olcRootPW: {SSHA}2e1yDU9g9VSc8UArkfpi5KsjT9mSZxCN olcDbIndex: objectClass eq,pres olcDbIndex: ou,cn,mail,surname,givenname eq,pres,sub structuralObjectClass: olcHdbConfig entryUUID: b5baf318-0bee-1039-9713-29cc6215f8f1 creatorsName: cn=config createTimestamp: 20190516062222Z entryCSN: 20190516062222.</description>
    </item>
    
    <item>
      <title>Logical-Clock和Vector-Clock</title>
      <link>https://xiaozhujesus.github.io/post/logical-vector-clock/</link>
      <pubDate>Sun, 01 Mar 2020 19:12:46 +0800</pubDate>
      
      <guid>https://xiaozhujesus.github.io/post/logical-vector-clock/</guid>
      <description>早在在 1978 年，Leslie Lamport 就提出逻辑时钟的概念。在分布式环境中，通过一系列规则来定义逻辑时钟的变化。从而能通过逻辑时钟来对分布式系统中的事件的先后顺序进行判断。
逻辑时钟本质上定义了一种 happen before 关系，记作-&amp;gt;，a-&amp;gt;b 意味着所有的进程都“认可”事件 a 发生在事件 b 之前。happen before 关系满足传递性：即(a-&amp;gt;b &amp;amp;&amp;amp; b-&amp;gt;c)可以推导出(a-&amp;gt;c)。
Logical Clock lamport 逻辑时钟算法：
 每个事件对应一个 Lamport 时间戳，初始值为 0 如果事件在节点内发生，时间戳加 1 如果事件属于发送事件，时间戳加 1 并在消息中带上该时间戳 如果事件属于接收事件，时间戳 = Max(本地时间戳，消息中的时间戳) + 1  三个机器上各自跑着一个进程，分别为 P1,P2,P3，由于不同的机器上的物理时钟、CPU 负载、或者 CPU 频率不一样，所以不同的机器上的时钟速率可能是不同的，例当 P1 所在的机器 tick 了 6 次，P2 所在的机器 tick 了 8 次，就是异步网络中指的漂移时钟不同。
图中，P1 给 P2 发送了消息 m1，m1 上附带了发送 m1 时的时钟 6，随后 P2 收到了 m1，根据 P2 接收到 m1 时的时钟，认为传输消息花了 16-6=10 个 tick，随后，P3 给 P2 发送消息 m3，m3 附带的发送时钟是 60。由于 P2 的时钟走的比 P3 的慢，所以接收到 m3 时，本机的时钟 56 比发送时钟 60 小，这是不合理的，需要调整时钟，如图中，将 P2 的 56 调整为 61，即 m3 的发送时钟加 1。</description>
    </item>
    
  </channel>
</rss>